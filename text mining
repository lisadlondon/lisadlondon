#Text Transformations
words.vec <- VectorSource(sba)
words.corpus <- Corpus(words.vec)
words.corpus

words.corpus <- tm_map(words.corpus,
                       content_transformer(tolower))
words.corpus <- tm_map(words.corpus, removePunctuation)
words.corpus <- tm_map(words.corpus, removeNumbers)
words.corpus <- tm_map(words.corpus, removeWords, stopwords("english"))

#Creating a TermDocumentMatrix
tdm <- TermDocumentMatrix(words.corpus)
tdm

#Create a word cloud
m <- as.matrix(tdm)
wordCounts <- rowSums(m)
wordCounts <- sort(wordCounts, decreasing=T)
head(wordCounts)

cloudFrame <- data.frame( + word=names(sortedMatrix), freq=sortedMatrix)
wordcloud(cloudFrame$word, cloudFrame$freq)

wordcloud(names(wordCounts), wordCounts, min.freq=2, +
            max.words=50, rot.per=0.35, colors=brewer.pal(8, "Dark2"))

#Read uploaded file
require(wordcloud)

#read the file
input <- readLines(nameoffile)

tail(input,20)
str(input)

#use TM package
#create the word list with counts
words.vec <- VectorSource(input)
words.corpus <- Corpus(words.vec)
words.corpus

tdm <- TermDocumentMatrix(words.corpus)

#explore the creation
str(tdm)
inspect(tdm[1:20,1:20])

m < as.matrix(tdm)
wordCounts <- rowSums(m)
head(wordCounts)

wordCounts <- sort(wordCounts, decreasing = T)
head(wordCounts)

wordcloud(names(wordCounts), wordCounts)

#remove unnecessary words
words.corpus <- tm_map(words.corpus, content_transformer(tolower))
words.corpus <- tm_map(words.corpus, removePunctuation)
words.corpus <- tm_map(words.corpus, removeNumbers)
words.corpus <- tm_map(words.corpus, removeWords, stopwords("english"))

#recreate word count
m < as.matrix(tdm)
wordCounts <- rowSums(m)
wordCounts <- sort(wordCounts, decreasing = T)
head(wordCounts, 20)

cloudFrame <- data.frame(word=names(wordCounts), freq=wordCounts)
wordcloud(names(wordCounts), wordCounts)

wordcloud(names(wordCounts), wordCounts, min.freq=3, max.words=50)
wordcloud(names(wordCounts), wordCounts, min.freq=3, max.words=50, rot.per=0.5)
wordcloud(names(wordCounts), wordCounts, min.freq=2, max.words=50, rot.per=0.35, colors=brewer.pal(8, "Dark2"))

#find associated words
findAssocs(tdm, "data", 0.6)
findAssocs(tdm, "course", 0.6)

#Sentiment Analysis
#access to positive and negative words:
https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html

pos <- "positive-words.txt"
neg <- "negative-words.txt"

#read the files
p <- scan(pos, character(0), sep="/n")
#separate each word
n <- scan(neg, character(0), sep="/n")

p <- p[-1:-34]
n <- n[-1:-34]

head(p,10)
head(n,10)

#calculate the total number of words
totalWords <- sum(wordCounts)

#have a vector that has all the words
words <- names(wordCounts)

matched <- match(words, p, nomatch=0)
head(matched, 10)

#Calculate the Positive Word Count
mCounts <- wordCounts[which(matched!=0)]
length(mCounts)

mWords <- names(mCounts)
nPos <- sum(mCounts)
nPos

#Calculate the Neg Word Count
matched <- match(words, n, nomatch=0)
nCounts <- wordCounts[which(matched!=0)]
nNeg <- sum(nCounts)
nWords <- names(nCounts)
nNeg
length(nCounts)

#Calculate the Sentiment
#% of words that are positive or negative
totalWords <- length(words)
ratioPos <- nPos/totalWords
ratioPos

ratioNeg <- nNe/totalWords
ratioNeg
